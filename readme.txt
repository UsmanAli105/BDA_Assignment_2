In this assignment we have to create a star-schema using an ETL pipeline and then perform analysis 
The breakdown of this assignment is as following:
	1. Write queries for database and tables creation, data insertion and table deletion in "Create_Table_queries.py"
	2. Modify connection string in "Create_Tables.py" according to your postgreSQL configurations 
	3. Write required code in jupyter notebook named as "extract_transform_load". To goal of this notebook is to create tables, extract data from json files, tranform it and load it in tables created in star-schema format. To understand star-schema you can explore attached figure of required star-schema. Please have a close look on comments and instructions in notebooks. 
	4. Test if your code works well by running "test_tables" notebook. If it display all tables you are okay to go to the next step
	5. Write code in analysis notebook according to given queries.

Marks for each step: 6 + 0 + 8 + 1 + 15 
Total marks: 30

